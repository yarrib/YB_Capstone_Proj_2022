{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e62629-be61-4c25-94dc-f30b705530b4",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "<font color=\"purple\">fctProduction DW + v1 d365 Account Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c1ee0a-73d6-4ebc-bcac-361b6aca8f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af71a219-2d62-4170-865a-b0a2f53d591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/wdw_Production_2020_to_2022_FY.csv',low_memory=False)\n",
    "\n",
    "# handle unicode issues with this d365 sourced csv\n",
    "# its a microsoft file so it makes sense it has the different encoding\n",
    "# iterate over our d365 account files (dictated by the advanced find import limits of 100k rows)\n",
    "d365_paths = ['./Data/d365_adv_find_Active_A-L.csv', './Data/d365_adv_find_Active_M-Z.csv','./Data/d365_adv_find_Active_nonAlphaStart.csv']\n",
    "dfs_d365 = []\n",
    "for p in d365_paths:\n",
    "    try:\n",
    "        tmp = pd.read_csv(p, low_memory=False, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        tmp = pd.read_csv(p, low_memory=False, encoding='windows-1252')\n",
    "    #display(tmp.head(2))\n",
    "    dfs_d365.append(tmp)\n",
    "    del tmp\n",
    "df2 = pd.concat(dfs_d365)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63822e07-bc99-4f53-8a1f-1dc6b1947016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130374 entries, 0 to 130373\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   JobId                130374 non-null  int64  \n",
      " 1   AssociateID          130374 non-null  int64  \n",
      " 2   OfficeCity           130353 non-null  object \n",
      " 3   OfficeState          130233 non-null  object \n",
      " 4   OfficeZip            130233 non-null  float64\n",
      " 5   OfficeName           130353 non-null  object \n",
      " 6   AccountGUID          130374 non-null  object \n",
      " 7   AccountName          130374 non-null  object \n",
      " 8   AccountCity          130341 non-null  object \n",
      " 9   AccountState         130341 non-null  object \n",
      " 10  AccountZip           130317 non-null  object \n",
      " 11  AccountNaicsName     130356 non-null  object \n",
      " 12  MarketName           130374 non-null  object \n",
      " 13  ServiceName          130374 non-null  object \n",
      " 14  ServiceLineName      130374 non-null  object \n",
      " 15  IndustryName         130374 non-null  object \n",
      " 16  JobTaxComplexity     14768 non-null   object \n",
      " 17  JobName              130371 non-null  object \n",
      " 18  CalendarYear         130374 non-null  int64  \n",
      " 19  ChargeHours          130374 non-null  float64\n",
      " 20  ProductionRevActual  130374 non-null  float64\n",
      " 21  Cost                 98169 non-null   float64\n",
      " 22  NumAssociatesOnJob   130374 non-null  int64  \n",
      "dtypes: float64(4), int64(4), object(15)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de86db22-4d2f-4691-a0a9-804e0f939a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 154514 entries, 0 to 1659\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   (Do Not Modify) Account ID    154514 non-null  object \n",
      " 1   (Do Not Modify) Row Checksum  154514 non-null  object \n",
      " 2   (Do Not Modify) Modified On   154514 non-null  object \n",
      " 3   Account Name                  154514 non-null  object \n",
      " 4   # of Locations                5693 non-null    float64\n",
      " 5   Annual Sales                  33752 non-null   object \n",
      " 6   Assets                        1915 non-null    object \n",
      " 7   Employees                     24232 non-null   object \n",
      " 8   SEC/Publicly Traded           154513 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(df.info())\n",
    "display(df2.info())\n",
    "#df2['Assets'].value_counts()\n",
    "#df2[df2['# of Locations'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172cc318-e7ad-486d-a17e-34a10953452d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "33252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "130374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# column refinements df \n",
    "df['JobTaxComplexity'].replace({np.nan:'Not Applicable'}, inplace=True) # fill complexity to not applicable\n",
    "df['Cost'].replace({np.nan:0}, inplace=True) # replace cost with 0 when its blank\n",
    "\n",
    "\n",
    "# SHOULD DO THIS IS THE SQL DATA ACQUISITION QUERY\n",
    "# only consider clients because those prospect jobs have no wip or any real financial info\n",
    "# df = df[df['AccountRelationshipType'] == 'Client']\n",
    "# df.drop(columns=['AccountRelationshipType'], inplace=True)\n",
    "\n",
    "# number of unique cols where we don't have a -9 (unknown) associate\n",
    "display(df[df['AssociateID'] != -9].JobId.nunique())\n",
    "# number of uniqu cols with known associates\n",
    "display(df[df['AssociateID'] == -9].shape[0])\n",
    "display(df.shape[0])\n",
    "display(df['JobId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4f5bb5-696e-4b22-a9b2-740b264261c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41458"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifying unique work items\n",
    "pd.concat([df['JobId'], df['ServiceName'], df['JobName'], df['CalendarYear']]).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2eb479-6274-42bb-a27f-eb4ac4688f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5M - 9.9M        8902\n",
       " 50M - 99M        3916\n",
       " 10M - 24.9M      3332\n",
       " Unknown          3236\n",
       " 1M - 2.4M        2681\n",
       " $200K - $499K    2607\n",
       " Under $200K      2506\n",
       " $500K - $999K    2431\n",
       " 2.5M - 4.9M      2239\n",
       " 25M - 49M        1022\n",
       " 100M - 249M       474\n",
       " 250M - 499M       197\n",
       " 750M - 999M        68\n",
       " 500M - 749M        61\n",
       " 1B - 1.49B         37\n",
       " 2B +               28\n",
       " 1.5B - 1.9B        15\n",
       " Name: Annual Sales, dtype: int64,\n",
       " 120762)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking our categories, this is just an example\n",
    "df2['Annual Sales'].value_counts(), df2['Annual Sales'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19793be-e953-4804-8cd4-6b593cb08db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Locations: 96.32% nulls\n",
      "Annual Sales: 78.16% nulls\n",
      "Assets: 98.76% nulls\n",
      "Employees: 84.32% nulls\n",
      "SEC/Publicly Traded: 0.00% nulls\n"
     ]
    }
   ],
   "source": [
    "for col in df2.columns:\n",
    "    null_pct = (df2[col].isna().sum()/df2.shape[0])*100\n",
    "    if null_pct > 0.:\n",
    "        print(f\"{col}: {null_pct:,.2f}% nulls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd362e1-34c8-4690-8a2e-9a150b2e83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column refinements df2\n",
    "# should this be done in the pipeline????\n",
    "df2['# of Locations'].replace({np.nan:0.},inplace=True) # encode unknown as a huge number so its categorical\n",
    "df2['Annual Sales'].fillna('Unknown',inplace=True)# mark as unknown\n",
    "df2['Assets'].fillna('Unknown', inplace=True)# mark as unknown\n",
    "df2['Employees'].replace({np.nan:'Unknown', '9-Jan':'1 - 9'\n",
    "                          , '24-Oct':'10 - 24'},inplace=True) #adjust some of the employee numbers that are interpolated as dates \n",
    "df2['SEC/Publicly Traded'].fillna('No',inplace=True) # fill the rare case of missing with No\n",
    "\n",
    "\n",
    "df2.drop(columns=['(Do Not Modify) Row Checksum','(Do Not Modify) Modified On'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee9aaa-5b3d-454b-a7ef-5dcbc3dc5fd0",
   "metadata": {},
   "source": [
    "---\n",
    "## Now that the preliminary data cleanup has been completed, we can group our fctProduction oriented data to the Job Level (by JobKey) and then join it to our d365 account data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a76d1e-aec1-4e0d-84d2-16baebfcac25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36937, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# group by for the wdw df(need to revise sql query\n",
    "# SHOULD THE GROUP BY EXCLUDE NULL ASSOCIATE KEYS ? E.G.\n",
    "# rollup associate sublevel to job (removing AssociateKey as a grouper)\n",
    "df_grouped = df.groupby(by=['JobId','CalendarYear','OfficeCity', 'OfficeState', 'OfficeZip',\n",
    "       'OfficeName', 'AccountGUID','AccountName', 'AccountCity', 'AccountState',\n",
    "       'AccountZip', 'AccountNaicsName',\n",
    "       'MarketName', 'ServiceName', 'ServiceLineName', 'IndustryName',\n",
    "       'JobTaxComplexity', 'JobName']).agg(\n",
    "    {\n",
    "        'ChargeHours':'sum', 'ProductionRevActual':'sum',\n",
    "        'Cost':'sum', 'NumAssociatesOnJob':'sum'\n",
    "    }\n",
    ")\n",
    "# reset our index\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "# drop rows where we have null values in the target\n",
    "display(df_grouped.shape)\n",
    "# DEPRECATED: only need the below if you do something in agg() like {'ChargeHours':['sum', 'mean']} which creates multiple levels on the column axis\n",
    "#df_grouped.columns = ['_'.join(col) if len(col[-1]) > 0 else col[0]  for col in df_grouped.columns.values]\n",
    "\n",
    "\n",
    "\n",
    "#df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87924635-c9f4-41ab-a780-12f920356987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobId                  29070\n",
       "CalendarYear               3\n",
       "OfficeCity                41\n",
       "OfficeState               15\n",
       "OfficeZip                 41\n",
       "OfficeName                41\n",
       "AccountGUID            13463\n",
       "AccountName            13463\n",
       "AccountCity             2324\n",
       "AccountState              52\n",
       "AccountZip              3153\n",
       "AccountNaicsName         834\n",
       "MarketName                16\n",
       "ServiceName              134\n",
       "ServiceLineName            2\n",
       "IndustryName               9\n",
       "JobTaxComplexity           4\n",
       "JobName                12229\n",
       "ChargeHours             5421\n",
       "ProductionRevActual    16076\n",
       "Cost                   22125\n",
       "NumAssociatesOnJob        32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062b905e-5874-43bf-9802-4700445169f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775db1a8-7b24-4400-bfe8-7d387b7a12cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35784, 29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(left=df_grouped, right=df2, how='inner',left_on='AccountGUID', right_on='(Do Not Modify) Account ID')\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee9bb4d-aea6-4e42-9815-0aebd8dc15ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobId': 28152,\n",
       " 'CalendarYear': 3,\n",
       " 'OfficeCity': 41,\n",
       " 'OfficeState': 15,\n",
       " 'OfficeZip': 41,\n",
       " 'OfficeName': 41,\n",
       " 'AccountGUID': 13020,\n",
       " 'AccountName': 13020,\n",
       " 'AccountCity': 2280,\n",
       " 'AccountState': 52,\n",
       " 'AccountZip': 3098,\n",
       " 'AccountNaicsName': 831,\n",
       " 'MarketName': 16,\n",
       " 'ServiceName': 134,\n",
       " 'ServiceLineName': 2,\n",
       " 'IndustryName': 9,\n",
       " 'JobTaxComplexity': 4,\n",
       " 'JobName': 11876,\n",
       " 'ChargeHours': 5334,\n",
       " 'ProductionRevActual': 15713,\n",
       " 'Cost': 21552,\n",
       " 'NumAssociatesOnJob': 32,\n",
       " '(Do Not Modify) Account ID': 13020,\n",
       " 'Account Name': 13020,\n",
       " '# of Locations': 27,\n",
       " 'Annual Sales': 17,\n",
       " 'Assets': 17,\n",
       " 'Employees': 12,\n",
       " 'SEC/Publicly Traded': 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['JobId', 'CalendarYear', 'OfficeCity', 'OfficeState', 'OfficeZip',\n",
       "       'OfficeName', 'AccountGUID', 'AccountName', 'AccountCity',\n",
       "       'AccountState', 'AccountZip', 'AccountNaicsName', 'MarketName',\n",
       "       'ServiceName', 'ServiceLineName', 'IndustryName', 'JobTaxComplexity',\n",
       "       'JobName', 'ChargeHours', 'ProductionRevActual', 'Cost',\n",
       "       'NumAssociatesOnJob', '(Do Not Modify) Account ID', 'Account Name',\n",
       "       '# of Locations', 'Annual Sales', 'Assets', 'Employees',\n",
       "       'SEC/Publicly Traded'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set our merged df back to df\n",
    "df = merged\n",
    "display(dict(df.nunique()))\n",
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a3704-629a-4a41-902b-774c272cfdb7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Drop identifier cols so the analysis is properly ambigious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd6e65a6-3c29-4a79-b06a-0dedd5f48fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of unique job keys as a proportion of rows\n",
      "(aka what percentage of records belong to one JobId,JobName,ServiceName,CalendarYear\n",
      "\t\t112.03%\n",
      "shape: (35784, 29)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print('count of unique job keys as a proportion of rows\\n(aka what percentage of records belong to one JobId,JobName,ServiceName,CalendarYear')\n",
    "\n",
    "print(f'\\t\\t{(pd.concat([df.JobId, df.JobName, df.ServiceName, df.CalendarYear]).nunique() / df.shape[0])*100:,.2f}%')\n",
    "print(f'shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad6709bb-1eaa-4196-945a-f410177d0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(df.JobId.value_counts())\n",
    "d2 = {k:v for k,v in d.items() if v > 1}\n",
    "# d2 are the multirow records\n",
    "evaluate_dups = df[df['JobId'].isin([int(x) for x in d2.keys()])]\n",
    "#evaluate_dups[['(Do Not Modify) Account ID', 'JobId','AccountName', 'Account Name','Annual Sales', 'Assets', 'Employees',\n",
    "#       'SEC/Publicly Traded', 'Relationship Maturity']]#.to_csv('./Data/issues.csv',index=False)\n",
    "#evaluate_dups.head()#.to_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dbdfa42-338c-4e97-95c2-984d6997c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['JobId','(Do Not Modify) Account ID', 'AccountGUID', 'Account Name', 'AccountName']\n",
    "\n",
    "df= df.drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b2ac1e-68fe-48ff-a156-69eabb828688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output for use in EDA/modeling\n",
    "df.to_csv('./Data/clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38748a20-124b-41d7-80f9-7aed2767c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9.7",
   "language": "python",
   "name": "py397"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
